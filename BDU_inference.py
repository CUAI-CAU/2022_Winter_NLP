# -*- coding: utf-8 -*-
"""BDU_inference

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aJ2-P_fIpRwr0SAtrKqXG8HDG4vvTMKn
"""

from google.colab import drive
drive.mount('/content/drive')

#hanspell 다운
!pip install git+https://github.com/ssut/py-hanspell.git

#Huggingface의 Transformer 다운로드
!pip install git+https://github.com/huggingface/transformers

import re
import torch
from hanspell import spell_checker
from transformers import ElectraForMaskedLM, ElectraTokenizer

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

tokenizer = ElectraTokenizer.from_pretrained("monologg/koelectra-base-v3-generator")
model =  ElectraForMaskedLM.from_pretrained("monologg/koelectra-base-v3-generator")

#모델이 정의되어 있어야 합니다
def sent_generation(sent): #sent는 list형식이 아니고 그냥 str ~ '나 배 고프 '
                                                #이렇게 문장 마지막에 띄어쓰기(공백)가 하나 있으면 좋습니다.
                                                #공백이 없다면 [MASK]를 넣지 않습니다.
    input_sent = " [MASK] ".join(sent.split(" "))
    inputs = tokenizer(input_sent, return_tensors = 'pt')
    with torch.no_grad(): #requires_grad = False
        model.eval()
        logits = model(**inputs).logits 
        mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]   
    
        predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)

        token_list = []
        for token in predicted_token_id.tolist():
            token_list.append(tokenizer.decode(token))

        sentence = input_sent.split(" ")
        re_token_lst = []
        for token in token_list:
            re_token = re.sub("[^가-힣]", "", token)
            re_token_lst.append(re_token)
        i = 0
        for idx, word in enumerate(sentence): 
            if word == "[MASK]":
                sentence[idx] = re_token_lst[i] 
                i += 1 
        output = "".join(sentence)  

        spell_checked_output = spell_checker.check(output).as_dict()
        return spell_checked_output['checked']

if __name__ == '__main__':
    a = sent_generation('사실 지금 배 고프 ')
    print(a)